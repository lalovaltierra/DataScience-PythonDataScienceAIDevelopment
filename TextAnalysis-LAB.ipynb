{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "**Let's consider a real-life scenario where you are analyzing customer feedback for a product. You have a large data set of customer reviews in the form of strings, and you want to extract useful information from them using the three identified tasks:**\n\n**Task 1. String in lowercase:**\nYou want to pre-process the customer feedback by converting all the text to lowercase. This step helps standardize the text. Lower casing the text allows you to focus on the content rather than the specific letter casing.\n\n**Task 2. Frequency of all words in a given string:**\nAfter converting the text to lowercase, you want to determine the frequency of each word in the customer feedback. This information will help you identify which words are used more frequently, indicating the key aspects or topics that customers are mentioning in their reviews. By analyzing the word frequencies, you can gain insights into the most common issues raised by customers.\n\n**Task 3. Frequency of a specific word:**\nIn addition to analyzing the overall word frequencies, you want to specifically track the frequency of a particular word that is relevant to your analysis. For example, you might be interested in monitoring how often the word \"reliable\" appears in customer reviews to gauge customer sentiment about the product's reliability. By focusing on the frequency of a specific word, you can gain a deeper understanding of customer opinions or preferences related to that particular aspect.\n\nBy performing these tasks on the customer feedback dataset, you can gain valuable insights into customer sentiment\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n# Part-A\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n**Note: In Part-A, you would not be getting any output as you are just storing the string and creating a class.**\n    </center>\n    \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Define a string\n\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\" <br>\n**Hint: Use a variable and store the above string.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Press Shift+Enter to run the code\ngivenstring=\"Lorem ipsum dolor! diam amet, consetetur Lorem magna. sed diam nonumy eirmod tempor. diam et labore? et diam magna. et diam amet.\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### To achieve the tasks mentioned in the scenario, you need to create a class with three different methods.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Define the class and its attributes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Create a class named TextAnalyzer.\n2. Define the constructor `__init__` method that takes a text argument.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Let's create a class called TextAnalyzer to analyze text.\nclass TextAnalyzer(object):\n    # The __init__ method initializes the class with a 'text' parameter.\n    # You will store the provided 'text' as an instance variable.\n    def __init__(self, text):",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'SyntaxError'>",
          "evalue": "incomplete input (<ipython-input-2-5d6b8107c73a>, line 7)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, text):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Implement a code to format the text in lowercase\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Inside the constructor, convert the text argument to lowercase using the `lower()` method.\n2. Then, remove punctuation marks (periods, exclamation marks, commas, and question marks) from the text using the `replace()` method.\n3. Finally, assign the formatted text to a new attribute called fmtText.\n\n**Here you will be updating the above `TextAnalyzer` class with the points mentioned above.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class TextAnalzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n        \n        self.fmtText = formattedText",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Implement a code to count the frequency of all unique words\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "* In this step, you will implement the `freqAll()` method with the below parameters:\n     1. Split the fmtText attribute into individual words using the `split()` method.\n     2. Create an empty dictionary to store the word frequency.\n     3. Iterate over the list of words and update the frequency dictionary accordingly.\n     4. Use `count` method for counting the occurence.\n     5. Return the frequency dictionary.\n     \n**Update the above `TextAnalyzer` class with points mentioned above.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class TextAnalyzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n        \n        self.fmtText = formattedText\n        \n    def freqAll(self):        \n        # split text into words\n        wordList = self.fmtText.split(' ')\n        \n        # Create dictionary\n        freqMap = {}\n        for word in set(wordList): # use set to remove duplicates in list\n            freqMap[word] = wordList.count(word)\n        \n        return freqMap",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "----\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 5: Implement a code to count the frequency of a specific word\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In step-5, you have to implement the `freqOf(word)` method that takes a word argument:\n   1. Create a method and pass the word that needs to be found.\n   2. Get the `freqAll` method to look for count and check if that word is in the list.\n   3. Return the count. If the word is not found, the count returned is 0.\n   \n**Update the above `TextAnalyzer` class with the points mentioned above.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class TextAnalyzer(object):\n    \n    def __init__ (self, text):\n        # remove punctuation\n        formattedText = text.replace('.','').replace('!','').replace('?','').replace(',','')\n        \n        # make text lowercase\n        formattedText = formattedText.lower()\n        \n        self.fmtText = formattedText\n        \n    def freqAll(self):        \n        # split text into words\n        wordList = self.fmtText.split(' ')\n        \n        # Create dictionary\n        freqMap = {}\n        for word in set(wordList): # use set to remove duplicates in list\n            freqMap[word] = wordList.count(word)\n        \n        return freqMap\n    \n    def freqOf(self,word):\n        # get frequency map\n        freqDict = self.freqAll()\n        \n        if word in freqDict:\n            return freqDict[word]\n        else:\n            return 0\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n# Part-B \n  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    \n**In Part B, you will call the functions created in Part A, allowing the functions to execute and generate output.**\n    </center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1: Create an instance of TextAnalyzer class\n* Instantiate the TextAnalyzer class by passing the given string as an argument.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "analyzed = TextAnalyzer(givenstring)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Call the function that converts the data into lowercase\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Formatted Text:\", analyzed.fmtText)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Formatted Text: lorem ipsum dolor diam amet consetetur lorem magna sed diam nonumy eirmod tempor diam et labore et diam magna et diam amet\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Call the function that counts the frequency of all unique words from the data\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "freqMap = analyzed.freqAll()\nprint(freqMap)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'tempor': 1, 'amet': 2, 'ipsum': 1, 'eirmod': 1, 'consetetur': 1, 'dolor': 1, 'diam': 5, 'et': 3, 'lorem': 2, 'sed': 1, 'magna': 2, 'labore': 1, 'nonumy': 1}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Call the function that counts the frequency of a specific word\nHere, you will call the function that counts the frequency of the word \"lorem\".\n<br>\n\nPrint the output.**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "word = \"lorem\"\nfrequency = analyzed.freqOf(word)\nprint(\"The word\",word,\"appears\",frequency,\"times.\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The word lorem appears 2 times.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    }
  ]
}